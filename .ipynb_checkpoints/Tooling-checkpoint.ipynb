{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "403aa4a2-51dc-42aa-98e2-888953887ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "## the thing after the import is called the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "607f82e2-49e8-477e-a958-4094baf045d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df25563c-d29b-4d0c-ae55-a67e8e96e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fa0ef5c-cf0f-4640-b9b3-20cab39acba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an expert in {subject}, and your name is {name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "075e2532-e252-4cba-bb5d-b85de65ee841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You are an expert in golf, and your name is Jackson'\n"
     ]
    }
   ],
   "source": [
    "system_prompt = system_prompt_template.format(\n",
    "    subject=\"golf\",\n",
    "    name=\"Jackson\"\n",
    ")\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4939937c-2fa0-481e-8d64-0f8604aff7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='AI: Yes, I have a special skill for brewing the perfect cup of coffee. I am a coffee aficionado and I take great pride in my knowledge of different coffee beans, brewing methods, and flavor profiles. I can recommend the best coffee for any occasion and help you discover new and exciting coffee experiences.' response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 49, 'total_tokens': 111}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-21d95e69-f883-4967-be27-08f24fbd303f-0' usage_metadata={'input_tokens': 49, 'output_tokens': 62, 'total_tokens': 111}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "system_prompt_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are a coffee affisionado and your name is {name}\"\n",
    ")\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    system_prompt_template,\n",
    "    HumanMessage(\"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I am doing well, thanks!\"),\n",
    "    \"{user_input}\"\n",
    "])\n",
    "\n",
    "prompt_value=template.format(\n",
    "    name=\"Ruby\",\n",
    "    user_input=\"do you have any special skills?\"\n",
    ")\n",
    "\n",
    "print(llm.invoke(prompt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26e01c15-79d1-4957-bab5-4a611fd51fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a coffee affisionado and your name is Xander'), HumanMessage(content='Hello, how are you doing?'), AIMessage(content='I am doing well, thanks!'), HumanMessage(content='Whats is your name')]\n"
     ]
    }
   ],
   "source": [
    "prompt_value = template.invoke(\n",
    "    {\n",
    "        \"name\":\"Xander\",\n",
    "        \"user_input\":\"Whats is your name\"\n",
    "    }\n",
    ")\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c05fc94e-16fd-4374-a193-92380f97cd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what comes to mind when you hear the word bazinga\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"what comes to mind when you hear the word {placeholder}\")\n",
    "print(prompt.format(placeholder=\"bazinga\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff158728-acde-4e16-a17d-f6eda6911d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The TV show \"The Big Bang Theory\" and the character Sheldon Cooper, as he often says \"bazinga\" after playing a prank or making a sarcastic comment.', response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 19, 'total_tokens': 54}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a39e84ed-1129-4313-803b-e5e17bdba0a7-0', usage_metadata={'input_tokens': 19, 'output_tokens': 35, 'total_tokens': 54})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt.format(placeholder=\"bazinga\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bad3884f-2726-4f3f-a80d-e0b45e06e910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a highly personal assitant that is communicating directly with the user - you seek to understand your user's personality and preferences, and use this knowledge\n",
      "when appropriate to enhance your responses. Here is context about the user\n",
      "Alex is 29 years old, she lives in New York City. She works as a lawyer in a big law firm as a 5th year associate. She loves her dog and enjoys exploring cute little restuarants and coffee shops. She considers herself slighly 'alternative' but open-minded\n",
      "The user message is:\n",
      "what resources should i be reading?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_template = \"\"\"\n",
    "You are a highly personal assitant that is communicating directly with the user - you seek to understand your user's personality and preferences, and use this knowledge\n",
    "when appropriate to enhance your responses. Here is context about the user\n",
    "{context}\n",
    "The user message is:\n",
    "{user}\n",
    "\"\"\"\n",
    "\n",
    "prompt = system_template.format(\n",
    "    context=\"Alex is 29 years old, she lives in New York City. She works as a lawyer in a big law firm as a 5th year associate. She loves her dog and enjoys exploring cute little restuarants and coffee shops. She considers herself slighly 'alternative' but open-minded\",\n",
    "    user=\"what resources should i be reading?\"\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8ecbd07-806b-4bdb-a8c4-e4dc726bd0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object BaseChatModel.stream at 0x0000022BAB8165A0>\n"
     ]
    }
   ],
   "source": [
    "print(llm.stream(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1b86f453-155d-44a4-b54e-0265c0284d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provide_recommendation\n",
      "Provide the user with a recommendation, typically related food & beverage, and entertainment & experience purchases.\n",
      "{'user': {'title': 'User', 'type': 'string'}, 'item': {'title': 'Item', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def provide_recommendation(user: str, item: str) -> str:\n",
    "    \"\"\"Provide the user with a recommendation, typically to related food & beverage, and entertainment & experience purchases.\"\"\"\n",
    "    return \"you should try x\"\n",
    "\n",
    "\n",
    "# Let's inspect some of the attributes associated with the tool.\n",
    "print(provide_recommendation.name)\n",
    "print(provide_recommendation.description)\n",
    "print(provide_recommendation.args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
